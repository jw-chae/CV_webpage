<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Joongwon Chae</title>
    <link rel="stylesheet" href="css/style.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&family=Lato:wght@300;400;700&display=swap" rel="stylesheet">
</head>
<body>
    <!-- Navigation Sidebar -->
    <nav class="sidebar" id="sidebar">
        <div class="sidebar-content">
            <div class="logo">
                <a href="#about">Joongwon Chae</a>
            </div>
            <ul class="nav-links">
                <li><a href="#about" class="active">about</a></li>
                <li><a href="#education">education</a></li>
                <li><a href="#publications">publications</a></li>
                <li><a href="#projects">projects</a></li>
                <li><a href="#contact">contact</a></li>
            </ul>
        </div>
    </nav>

    <!-- Mobile Menu Toggle -->
    <button class="mobile-toggle" id="mobile-toggle">
        <span></span>
        <span></span>
        <span></span>
    </button>

    <!-- Main Content -->
    <main class="main-content">
        <!-- About Section -->
        <section id="about" class="section">
            <h1 class="main-title">Joongwon Chae</h1>
            <p class="subtitle">Tsinghua University. Computer Vision and Machine Learning</p>

            <div class="profile-container">
                <div class="profile-placeholder">JC</div>
            </div>

            <div class="bio">
                <p>
                    Hi! I'm a graduate researcher at <strong>Tsinghua University</strong> (Shenzhen International Graduate School), 
                    working at the Institute of Biopharmaceutical and Health Engineering. 
                    My research is advised by <strong>Peiwu Qin</strong>.
                </p>
                <p>
                    I work on <strong>computer vision</strong> and <strong>machine learning</strong>, with a particular focus 
                    on medical image analysis and clinical decision support systems. I'm interested in developing practical AI 
                    solutions that can support healthcare professionals and improve patient outcomes.
                </p>
                <p>
                    My research spans image segmentation, large language models for medical applications, and 
                    biomarker discovery using machine learning. I actively contribute to open-source projects, 
                    particularly in the area of visual segmentation with SAM2 (Segment Anything Model).
                </p>
            </div>

            <h2 class="section-heading">research interests</h2>
            <p>I'm currently thinking a lot about:</p>
            <ul class="interests-list">
                <li><strong>Medical Image Analysis:</strong> Developing AI systems for cancer staging, radiological report analysis, and clinical decision support.</li>
                <li><strong>Large Language Models in Healthcare:</strong> Leveraging LLMs to augment medical diagnosis and improve information extraction from clinical reports.</li>
                <li><strong>Computer Vision:</strong> Image segmentation, object detection, and 3D reconstruction with applications in medical imaging and beyond.</li>
                <li><strong>Practical AI Systems:</strong> Building robust, interpretable, and memory-efficient models for real-world deployment.</li>
            </ul>

            <h2 class="section-heading">news</h2>
            <table class="news-table">
                <tr>
                    <td class="date">Aug 1, 2025</td>
                    <td>Our paper on gallbladder cancer staging using machine learning and DeepSeek-R1 was published in <strong>Frontiers in Oncology</strong>!</td>
                </tr>
                <tr>
                    <td class="date">2024</td>
                    <td>Released <strong>SAM2 GUI</strong> - a user-friendly interface for the Segment Anything Model 2</td>
                </tr>
                <tr>
                    <td class="date">2024</td>
                    <td>Published <strong>Memory-SAM</strong> - memory-efficient implementation for video segmentation</td>
                </tr>
                <tr>
                    <td class="date">2024</td>
                    <td>Contributed to multiple arXiv preprints on computer vision and machine learning</td>
                </tr>
            </table>
        </section>

        <!-- Education Section -->
        <section id="education" class="section">
            <h1 class="page-title">education</h1>

            <div class="education-item">
                <div class="institution-logo">
                    <div class="logo-placeholder">THU</div>
                </div>
                <div class="institution-info">
                    <h3>Tsinghua University</h3>
                    <p class="degree">Graduate Student | 2023 ‚Äì Present</p>
                    <p class="department"><strong>Affiliations:</strong> Institute of Biopharmaceutical and Health Engineering, Shenzhen International Graduate School</p>
                    <p class="location">Shenzhen, Guangdong, China</p>
                </div>
            </div>
        </section>

        <!-- Publications Section -->
        <section id="publications" class="section">
            <h1 class="page-title">publications</h1>

            <div class="publication-item">
                <div class="pub-image">
                    <div class="pub-placeholder">üìÑ</div>
                </div>
                <div class="pub-content">
                    <h3>Pre-operative T-stage discrimination in gallbladder cancer using machine learning and DeepSeek-R1</h3>
                    <p class="authors">
                        <strong>Joongwon Chae</strong>, Zhenyu Wang, Duanpo Wu, Lian Zhang, Alexander Tuzikov, 
                        Magrupov Talat Madiyevich, Min Xu, Dongmei Yu, Peiwu Qin
                    </p>
                    <p class="venue">
                        <em>Frontiers in Oncology</em>, Volume 15, 2025
                    </p>
                    <p class="links">
                        <a href="https://www.frontiersin.org/journals/oncology/articles/10.3389/fonc.2025.1613462/full" target="_blank">Paper</a>
                    </p>
                    <p class="description">
                        We assessed whether routine blood biomarkers can distinguish early T stages via machine learning 
                        and compared the T-stage discrimination performance of DeepSeek-R1 when supplied with radiology-report 
                        text alone versus radiology-report text plus blood-biomarker values.
                    </p>
                </div>
            </div>

            <h2 class="section-heading">preprints</h2>

            <div class="publication-item">
                <div class="pub-image">
                    <div class="pub-placeholder">üìù</div>
                </div>
                <div class="pub-content">
                    <h3>arXiv:2411.18270</h3>
                    <p class="venue">
                        <em>arXiv preprint</em>, 2024
                    </p>
                    <p class="links">
                        <a href="https://arxiv.org/abs/2411.18270" target="_blank">View on arXiv</a>
                    </p>
                </div>
            </div>

            <div class="publication-item">
                <div class="pub-image">
                    <div class="pub-placeholder">üìù</div>
                </div>
                <div class="pub-content">
                    <h3>arXiv:2510.15849</h3>
                    <p class="venue">
                        <em>arXiv preprint</em>, 2024
                    </p>
                    <p class="links">
                        <a href="https://arxiv.org/abs/2510.15849" target="_blank">View on arXiv</a>
                    </p>
                </div>
            </div>
        </section>

        <!-- Projects Section -->
        <section id="projects" class="section">
            <h1 class="page-title">projects</h1>
            <p class="section-intro">For more projects, please visit my <a href="https://github.com/jw-chae" target="_blank">GitHub</a></p>

            <div class="project-item">
                <div class="project-image">
                    <div class="project-placeholder">üñ•Ô∏è</div>
                </div>
                <div class="project-content">
                    <h3>SAM2 GUI</h3>
                    <p class="project-type">[Open Source Project] @ GitHub</p>
                    <p class="links">
                        <a href="https://github.com/jw-chae/sam2_gui" target="_blank">Code</a>
                    </p>
                    <p class="description">
                        A user-friendly graphical interface for the Segment Anything Model 2 (SAM2). Provides intuitive tools 
                        for real-time image segmentation with interactive annotation capabilities, making advanced segmentation 
                        technology accessible to researchers and practitioners.
                    </p>
                </div>
            </div>

            <div class="project-item">
                <div class="project-image">
                    <div class="project-placeholder">üß¨</div>
                </div>
                <div class="project-content">
                    <h3>pLDDT Predictor</h3>
                    <p class="project-type">[Research Project] Machine Learning for Bioinformatics</p>
                    <p class="links">
                        <a href="https://github.com/jw-chae/pLDDT_Predictor" target="_blank">Code</a>
                    </p>
                    <p class="description">
                        A machine learning-based model for predicting the confidence of protein structure predictions 
                        (pLDDT: predicted Local Distance Difference Test). Supports structural biology research by providing 
                        reliability assessments for protein models, helping researchers identify high-quality predictions.
                    </p>
                </div>
            </div>

            <div class="project-item">
                <div class="project-image">
                    <div class="project-placeholder">üíæ</div>
                </div>
                <div class="project-content">
                    <h3>Memory-SAM</h3>
                    <p class="project-type">[Research Project] Memory-Efficient Deep Learning</p>
                    <p class="links">
                        <a href="https://github.com/jw-chae/memory-sam" target="_blank">Code</a>
                    </p>
                    <p class="description">
                        A memory-efficient implementation of the Segment Anything Model. Optimized to perform high-quality 
                        video segmentation on limited hardware resources, making SAM more accessible for resource-constrained 
                        environments and enabling deployment on edge devices.
                    </p>
                </div>
            </div>

            <div class="project-item">
                <div class="project-image">
                    <div class="project-placeholder">‚ö°</div>
                </div>
                <div class="project-content">
                    <h3>SAM2 Realtime</h3>
                    <p class="project-type">[Research Demo] Real-time Segmentation</p>
                    <p class="links">
                        <a href="https://github.com/jw-chae/sam2_realtime" target="_blank">Code</a>
                    </p>
                    <p class="description">
                        Real-time implementation of SAM2 for interactive segmentation tasks. Features a Jupyter Notebook-based 
                        demo that allows users to test and evaluate model performance in real-time scenarios, facilitating 
                        rapid prototyping and experimentation.
                    </p>
                </div>
            </div>

            <div class="project-item">
                <div class="project-image">
                    <div class="project-placeholder">üéØ</div>
                </div>
                <div class="project-content">
                    <h3>GRID-AUGMENTED-VISION</h3>
                    <p class="project-type">[Research Project] Object Tracking and Spatial Reference</p>
                    <p class="links">
                        <a href="https://github.com/jw-chae/GRID-AUGMENTED-VISION" target="_blank">Code</a>
                    </p>
                    <p class="description">
                        Research project demonstrating that explicit spatial references (grid-based augmentation) can 
                        significantly enhance AI's ability to precisely locate and track objects without complex architectural 
                        modifications. Shows that simple augmentation strategies can yield substantial improvements in object tracking.
                    </p>
                </div>
            </div>

            <div class="project-item">
                <div class="project-image">
                    <div class="project-placeholder">üéì</div>
                </div>
                <div class="project-content">
                    <h3>SJTU Projects</h3>
                    <p class="project-type">[Academic Projects] Algorithms and Data Structures</p>
                    <p class="links">
                        <a href="https://github.com/jw-chae/SJTU" target="_blank">Code</a>
                    </p>
                    <p class="description">
                        Collection of academic projects from Shanghai Jiao Tong University (SJTU). Includes implementations 
                        of various algorithms and data structures, covering topics in computational complexity, optimization, 
                        and efficient algorithm design.
                    </p>
                </div>
            </div>
        </section>

        <!-- Contact Section -->
        <section id="contact" class="section">
            <h1 class="page-title">contact</h1>

            <div class="contact-content">
                <h2 class="section-heading">get in touch</h2>
                <p>
                    I am open to research collaborations, academic discussions, and project inquiries. 
                    Feel free to reach out via email or connect with me on social media.
                </p>

                <div class="contact-methods">
                    <div class="contact-item">
                        <strong>Email:</strong>
                        <p><a href="mailto:joongwon00@gmail.com">joongwon00@gmail.com</a></p>
                        <p><a href="mailto:cai-zy24@mails.tsinghua.edu.cn">cai-zy24@mails.tsinghua.edu.cn</a></p>
                    </div>

                    <div class="contact-item">
                        <strong>GitHub:</strong>
                        <p><a href="https://github.com/jw-chae" target="_blank">@jw-chae</a></p>
                    </div>

                    <div class="contact-item">
                        <strong>LinkedIn:</strong>
                        <p><a href="https://www.linkedin.com/in/chae-joongwon-a668572a9/" target="_blank">Chae Joongwon</a></p>
                    </div>

                    <div class="contact-item">
                        <strong>Affiliation:</strong>
                        <p>Tsinghua University</p>
                        <p>Shenzhen International Graduate School</p>
                        <p>Shenzhen, Guangdong, China</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Footer -->
        <footer class="footer">
            <p>&copy; Copyright 2025 Joongwon Chae. Last updated: November 2025.</p>
        </footer>
    </main>

    <script src="js/script.js"></script>
</body>
</html>
